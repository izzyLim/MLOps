{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/mlflow-venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
      "Token is valid (permission: fineGrained).\n",
      "Your token has been saved to /Users/yeji/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import functools\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import evaluate\n",
    "\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score, confusion_matrix, classification_report, balanced_accuracy_score, accuracy_score\n",
    "\n",
    "from datasets import Dataset, DatasetDict\n",
    "from peft import LoraConfig, prepare_model_for_kbit_training, get_peft_model\n",
    "\n",
    "from huggingface_hub import login\n",
    "\n",
    "import os \n",
    "\n",
    "login(token = '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')\n",
    "\n",
    "from transformers import (\n",
    "    AutoModelForSequenceClassification,\n",
    "    AutoTokenizer,\n",
    "    BitsAndBytesConfig,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    DataCollatorWithPadding\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labels</th>\n",
       "      <th>sentence</th>\n",
       "      <th>kor_sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neutral</td>\n",
       "      <td>According to Gran, the company has no plans to...</td>\n",
       "      <td>Granì— ë”°ë¥´ë©´, ê·¸ íšŒì‚¬ëŠ” íšŒì‚¬ê°€ ì„±ì¥í•˜ê³  ìˆëŠ” ê³³ì´ì§€ë§Œ, ëª¨ë“  ìƒì‚°ì„ ëŸ¬ì‹œì•„ë¡œ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>neutral</td>\n",
       "      <td>Technopolis plans to develop in stages an area...</td>\n",
       "      <td>í…Œí¬ë…¸í´ë¦¬ìŠ¤ëŠ” ì»´í“¨í„° ê¸°ìˆ ê³¼ í†µì‹  ë¶„ì•¼ì—ì„œ ì¼í•˜ëŠ” íšŒì‚¬ë“¤ì„ ìœ ì¹˜í•˜ê¸° ìœ„í•´ 10ë§Œ í‰...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>negative</td>\n",
       "      <td>The international electronic industry company ...</td>\n",
       "      <td>êµ­ì œ ì „ìì‚°ì—… íšŒì‚¬ì¸ ì—˜ì½”í…ì€ íƒˆë¦° ê³µì¥ì—ì„œ ìˆ˜ì‹­ ëª…ì˜ ì§ì›ì„ í•´ê³ í–ˆìœ¼ë©°, ì´ì „ì˜ ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>positive</td>\n",
       "      <td>With the new production plant the company woul...</td>\n",
       "      <td>ìƒˆë¡œìš´ ìƒì‚°ê³µì¥ìœ¼ë¡œ ì¸í•´ íšŒì‚¬ëŠ” ì˜ˆìƒë˜ëŠ” ìˆ˜ìš” ì¦ê°€ë¥¼ ì¶©ì¡±ì‹œí‚¬ ìˆ˜ ìˆëŠ” ëŠ¥ë ¥ì„ ì¦ê°€...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>positive</td>\n",
       "      <td>According to the company's updated strategy fo...</td>\n",
       "      <td>2009-2012ë…„ íšŒì‚¬ì˜ ì—…ë°ì´íŠ¸ëœ ì „ëµì— ë”°ë¥´ë©´, BaswareëŠ” 20% - 4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>neutral</td>\n",
       "      <td>In August, Latvijas Finieris ordered all produ...</td>\n",
       "      <td>8ì›”, ë€íŠ¸ë¹„ì•¼ìŠ¤ í”¼ë‹ˆì—ë¦¬ìŠ¤ëŠ” ë¦¬íˆ¬ì•„ë‹ˆì•„ ìš°í¬ë©”ë¥´ê²Œì— ìƒˆë¡œìš´ ë…¹ìƒ‰ ë² ë‹ˆì–´ ê³µì¥ì„ ì§€...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>positive</td>\n",
       "      <td>It delivers a different user experience and en...</td>\n",
       "      <td>ê·¸ê²ƒì€ ë‹¤ë¥¸ ì‚¬ìš©ì ê²½í—˜ì„ ì œê³µí•˜ê³  ìš°ë¦¬ê°€ ë‹¤ë£° ìˆ˜ ìˆëŠ” ì‹œì¥ì„ ë„“í ìˆ˜ ìˆê²Œ í•´ì¤...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>neutral</td>\n",
       "      <td>Jacobs has been supporting Storengy's investme...</td>\n",
       "      <td>JacobsëŠ” ì†Œìœ ì£¼ ì—”ì§€ë‹ˆì–´ë¡œ 2006ë…„ë¶€í„° Storengyì˜ ìŠ¤í† ë¦¬ì§€ ì‚¬ì´íŠ¸ ê°œ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>positive</td>\n",
       "      <td>ADPnews - Jun 30, 2009 - Finnish stainless ste...</td>\n",
       "      <td>ADPë‰´ìŠ¤ - 2009ë…„ 6ì›” 30ì¼ - í•€ë€ë“œ ìŠ¤í…Œì¸ë¦¬ìŠ¤ê°• ì œì¡°ì—…ì²´ì¸ Outoku...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>positive</td>\n",
       "      <td>Most of the increase in net sales was due to t...</td>\n",
       "      <td>ìˆœë§¤ì¶œ ì¦ê°€ì˜ ëŒ€ë¶€ë¶„ì€ ì •ì›ê³µêµ¬ì™€ ë³´íŠ¸ë¥¼ ìƒì‚°í•˜ëŠ” ìŠ¤ì›¨ë´ ì‹¤ë°”ë¥¼ ì¸ìˆ˜í–ˆê¸° ë•Œë¬¸ì´ë‹¤.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>499 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       labels                                           sentence  \\\n",
       "0     neutral  According to Gran, the company has no plans to...   \n",
       "1     neutral  Technopolis plans to develop in stages an area...   \n",
       "2    negative  The international electronic industry company ...   \n",
       "3    positive  With the new production plant the company woul...   \n",
       "4    positive  According to the company's updated strategy fo...   \n",
       "..        ...                                                ...   \n",
       "494   neutral  In August, Latvijas Finieris ordered all produ...   \n",
       "495  positive  It delivers a different user experience and en...   \n",
       "496   neutral  Jacobs has been supporting Storengy's investme...   \n",
       "497  positive  ADPnews - Jun 30, 2009 - Finnish stainless ste...   \n",
       "498  positive  Most of the increase in net sales was due to t...   \n",
       "\n",
       "                                          kor_sentence  \n",
       "0    Granì— ë”°ë¥´ë©´, ê·¸ íšŒì‚¬ëŠ” íšŒì‚¬ê°€ ì„±ì¥í•˜ê³  ìˆëŠ” ê³³ì´ì§€ë§Œ, ëª¨ë“  ìƒì‚°ì„ ëŸ¬ì‹œì•„ë¡œ...  \n",
       "1    í…Œí¬ë…¸í´ë¦¬ìŠ¤ëŠ” ì»´í“¨í„° ê¸°ìˆ ê³¼ í†µì‹  ë¶„ì•¼ì—ì„œ ì¼í•˜ëŠ” íšŒì‚¬ë“¤ì„ ìœ ì¹˜í•˜ê¸° ìœ„í•´ 10ë§Œ í‰...  \n",
       "2    êµ­ì œ ì „ìì‚°ì—… íšŒì‚¬ì¸ ì—˜ì½”í…ì€ íƒˆë¦° ê³µì¥ì—ì„œ ìˆ˜ì‹­ ëª…ì˜ ì§ì›ì„ í•´ê³ í–ˆìœ¼ë©°, ì´ì „ì˜ ...  \n",
       "3    ìƒˆë¡œìš´ ìƒì‚°ê³µì¥ìœ¼ë¡œ ì¸í•´ íšŒì‚¬ëŠ” ì˜ˆìƒë˜ëŠ” ìˆ˜ìš” ì¦ê°€ë¥¼ ì¶©ì¡±ì‹œí‚¬ ìˆ˜ ìˆëŠ” ëŠ¥ë ¥ì„ ì¦ê°€...  \n",
       "4    2009-2012ë…„ íšŒì‚¬ì˜ ì—…ë°ì´íŠ¸ëœ ì „ëµì— ë”°ë¥´ë©´, BaswareëŠ” 20% - 4...  \n",
       "..                                                 ...  \n",
       "494  8ì›”, ë€íŠ¸ë¹„ì•¼ìŠ¤ í”¼ë‹ˆì—ë¦¬ìŠ¤ëŠ” ë¦¬íˆ¬ì•„ë‹ˆì•„ ìš°í¬ë©”ë¥´ê²Œì— ìƒˆë¡œìš´ ë…¹ìƒ‰ ë² ë‹ˆì–´ ê³µì¥ì„ ì§€...  \n",
       "495  ê·¸ê²ƒì€ ë‹¤ë¥¸ ì‚¬ìš©ì ê²½í—˜ì„ ì œê³µí•˜ê³  ìš°ë¦¬ê°€ ë‹¤ë£° ìˆ˜ ìˆëŠ” ì‹œì¥ì„ ë„“í ìˆ˜ ìˆê²Œ í•´ì¤...  \n",
       "496  JacobsëŠ” ì†Œìœ ì£¼ ì—”ì§€ë‹ˆì–´ë¡œ 2006ë…„ë¶€í„° Storengyì˜ ìŠ¤í† ë¦¬ì§€ ì‚¬ì´íŠ¸ ê°œ...  \n",
       "497  ADPë‰´ìŠ¤ - 2009ë…„ 6ì›” 30ì¼ - í•€ë€ë“œ ìŠ¤í…Œì¸ë¦¬ìŠ¤ê°• ì œì¡°ì—…ì²´ì¸ Outoku...  \n",
       "498     ìˆœë§¤ì¶œ ì¦ê°€ì˜ ëŒ€ë¶€ë¶„ì€ ì •ì›ê³µêµ¬ì™€ ë³´íŠ¸ë¥¼ ìƒì‚°í•˜ëŠ” ìŠ¤ì›¨ë´ ì‹¤ë°”ë¥¼ ì¸ìˆ˜í–ˆê¸° ë•Œë¬¸ì´ë‹¤.  \n",
       "\n",
       "[499 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df = pd.read_csv(\"finance_data.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labels</th>\n",
       "      <th>sentence</th>\n",
       "      <th>kor_sentence</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neutral</td>\n",
       "      <td>According to Gran, the company has no plans to...</td>\n",
       "      <td>Granì— ë”°ë¥´ë©´, ê·¸ íšŒì‚¬ëŠ” íšŒì‚¬ê°€ ì„±ì¥í•˜ê³  ìˆëŠ” ê³³ì´ì§€ë§Œ, ëª¨ë“  ìƒì‚°ì„ ëŸ¬ì‹œì•„ë¡œ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>neutral</td>\n",
       "      <td>Technopolis plans to develop in stages an area...</td>\n",
       "      <td>í…Œí¬ë…¸í´ë¦¬ìŠ¤ëŠ” ì»´í“¨í„° ê¸°ìˆ ê³¼ í†µì‹  ë¶„ì•¼ì—ì„œ ì¼í•˜ëŠ” íšŒì‚¬ë“¤ì„ ìœ ì¹˜í•˜ê¸° ìœ„í•´ 10ë§Œ í‰...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>negative</td>\n",
       "      <td>The international electronic industry company ...</td>\n",
       "      <td>êµ­ì œ ì „ìì‚°ì—… íšŒì‚¬ì¸ ì—˜ì½”í…ì€ íƒˆë¦° ê³µì¥ì—ì„œ ìˆ˜ì‹­ ëª…ì˜ ì§ì›ì„ í•´ê³ í–ˆìœ¼ë©°, ì´ì „ì˜ ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>positive</td>\n",
       "      <td>With the new production plant the company woul...</td>\n",
       "      <td>ìƒˆë¡œìš´ ìƒì‚°ê³µì¥ìœ¼ë¡œ ì¸í•´ íšŒì‚¬ëŠ” ì˜ˆìƒë˜ëŠ” ìˆ˜ìš” ì¦ê°€ë¥¼ ì¶©ì¡±ì‹œí‚¬ ìˆ˜ ìˆëŠ” ëŠ¥ë ¥ì„ ì¦ê°€...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>positive</td>\n",
       "      <td>According to the company's updated strategy fo...</td>\n",
       "      <td>2009-2012ë…„ íšŒì‚¬ì˜ ì—…ë°ì´íŠ¸ëœ ì „ëµì— ë”°ë¥´ë©´, BaswareëŠ” 20% - 4...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     labels                                           sentence  \\\n",
       "0   neutral  According to Gran, the company has no plans to...   \n",
       "1   neutral  Technopolis plans to develop in stages an area...   \n",
       "2  negative  The international electronic industry company ...   \n",
       "3  positive  With the new production plant the company woul...   \n",
       "4  positive  According to the company's updated strategy fo...   \n",
       "\n",
       "                                        kor_sentence  target  \n",
       "0  Granì— ë”°ë¥´ë©´, ê·¸ íšŒì‚¬ëŠ” íšŒì‚¬ê°€ ì„±ì¥í•˜ê³  ìˆëŠ” ê³³ì´ì§€ë§Œ, ëª¨ë“  ìƒì‚°ì„ ëŸ¬ì‹œì•„ë¡œ...       1  \n",
       "1  í…Œí¬ë…¸í´ë¦¬ìŠ¤ëŠ” ì»´í“¨í„° ê¸°ìˆ ê³¼ í†µì‹  ë¶„ì•¼ì—ì„œ ì¼í•˜ëŠ” íšŒì‚¬ë“¤ì„ ìœ ì¹˜í•˜ê¸° ìœ„í•´ 10ë§Œ í‰...       1  \n",
       "2  êµ­ì œ ì „ìì‚°ì—… íšŒì‚¬ì¸ ì—˜ì½”í…ì€ íƒˆë¦° ê³µì¥ì—ì„œ ìˆ˜ì‹­ ëª…ì˜ ì§ì›ì„ í•´ê³ í–ˆìœ¼ë©°, ì´ì „ì˜ ...       0  \n",
       "3  ìƒˆë¡œìš´ ìƒì‚°ê³µì¥ìœ¼ë¡œ ì¸í•´ íšŒì‚¬ëŠ” ì˜ˆìƒë˜ëŠ” ìˆ˜ìš” ì¦ê°€ë¥¼ ì¶©ì¡±ì‹œí‚¬ ìˆ˜ ìˆëŠ” ëŠ¥ë ¥ì„ ì¦ê°€...       2  \n",
       "4  2009-2012ë…„ íšŒì‚¬ì˜ ì—…ë°ì´íŠ¸ëœ ì „ëµì— ë”°ë¥´ë©´, BaswareëŠ” 20% - 4...       2  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['labels']=df['labels'].astype('category')\n",
    "df['target']=df['labels'].cat.codes\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['negative', 'neutral', 'positive'], dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['labels'].cat.categories\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'negative', 1: 'neutral', 2: 'positive'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "category_map = {code: category for code, category in enumerate(df['labels'].cat.categories)}\n",
    "\n",
    "category_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(299, 4) (100, 4) (100, 4)\n"
     ]
    }
   ],
   "source": [
    "train_end_point = int(df.shape[0]*0.6)\n",
    "val_end_point = int(df.shape[0]*0.8)\n",
    "df_train = df.iloc[:train_end_point,:]\n",
    "df_val = df.iloc[train_end_point:val_end_point,:]\n",
    "df_test = df.iloc[val_end_point:,:]\n",
    "print(df_train.shape, df_test.shape, df_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Converting pandas DataFrames into Hugging Face Dataset objects:\n",
    "dataset_train = Dataset.from_pandas(df_train.drop('labels',axis=1))\n",
    "dataset_val = Dataset.from_pandas(df_val.drop('labels',axis=1))\n",
    "dataset_test = Dataset.from_pandas(df_test.drop('labels',axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Shuffle the training dataset\n",
    "dataset_train_shuffled = dataset_train.shuffle(seed=42)  # Using a seed for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['sentence', 'kor_sentence', 'target'],\n",
       "        num_rows: 299\n",
       "    })\n",
       "    val: Dataset({\n",
       "        features: ['sentence', 'kor_sentence', 'target'],\n",
       "        num_rows: 100\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['sentence', 'kor_sentence', 'target'],\n",
       "        num_rows: 100\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Combine them into a single DatasetDict\n",
    "dataset = DatasetDict({\n",
    "    'train': dataset_train_shuffled,\n",
    "    'val': dataset_val,\n",
    "    'test': dataset_test\n",
    "})\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['sentence', 'kor_sentence', 'target'],\n",
       "    num_rows: 299\n",
       "})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "dataset['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target\n",
       "2    0.896321\n",
       "1    0.100334\n",
       "0    0.003344\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.target.value_counts(normalize=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.9643, 0.0321, 0.0036])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "class_weights=(1/df_train.target.value_counts(normalize=True).sort_index()).tolist()\n",
    "class_weights=torch.tensor(class_weights)\n",
    "class_weights=class_weights/class_weights.sum()\n",
    "class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"meta-llama/Meta-Llama-3-8B\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "quantization_config = BitsAndBytesConfig(\n",
    "    load_in_4bit = True, # enable 4-bit quantization\n",
    "    bnb_4bit_quant_type = 'nf4', # information theoretically optimal dtype for normally distributed weights\n",
    "    bnb_4bit_use_double_quant = True, # quantize quantized weights //insert xzibit meme\n",
    "    bnb_4bit_compute_dtype = torch.bfloat16 # optimized fp format for ML\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "lora_config = LoraConfig(\n",
    "    r = 16, # the dimension of the low-rank matrices\n",
    "    lora_alpha = 8, # scaling factor for LoRA activations vs pre-trained weight activations\n",
    "    target_modules = ['q_proj', 'k_proj', 'v_proj', 'o_proj'],\n",
    "    lora_dropout = 0.05, # dropout probability of the LoRA layers\n",
    "    bias = 'none', # wether to train bias weights, set to 'none' for attention layers\n",
    "    task_type = 'SEQ_CLS'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"mps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:15<00:00,  3.98s/it]\n",
      "Some weights of LlamaForSequenceClassification were not initialized from the model checkpoint at meta-llama/Meta-Llama-3-8B and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LlamaForSequenceClassification(\n",
       "  (model): LlamaModel(\n",
       "    (embed_tokens): Embedding(128256, 4096)\n",
       "    (layers): ModuleList(\n",
       "      (0-31): 32 x LlamaDecoderLayer(\n",
       "        (self_attn): LlamaSdpaAttention(\n",
       "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "          (v_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
       "          (up_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
       "          (down_proj): Linear(in_features=14336, out_features=4096, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm()\n",
       "        (post_attention_layernorm): LlamaRMSNorm()\n",
       "      )\n",
       "    )\n",
       "    (norm): LlamaRMSNorm()\n",
       "  )\n",
       "  (score): Linear(in_features=4096, out_features=3, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.environ['PYTORCH_MPS_HIGH_WATERMARK_RATIO'] = '0.0'\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_name,\n",
    "    #quantization_config=quantization_config,\n",
    "    #device_map=\"mps\",\n",
    "    torch_dtype=torch.float16,\n",
    "    num_labels=3\n",
    ")\n",
    "\n",
    "model.to(\"mps\")\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not load bitsandbytes native library: dlopen(/opt/anaconda3/envs/mlflow-venv/lib/python3.12/site-packages/bitsandbytes/libbitsandbytes_cpu.dylib, 0x0006): tried: '/opt/anaconda3/envs/mlflow-venv/lib/python3.12/site-packages/bitsandbytes/libbitsandbytes_cpu.dylib' (no such file), '/System/Volumes/Preboot/Cryptexes/OS/opt/anaconda3/envs/mlflow-venv/lib/python3.12/site-packages/bitsandbytes/libbitsandbytes_cpu.dylib' (no such file), '/opt/anaconda3/envs/mlflow-venv/lib/python3.12/site-packages/bitsandbytes/libbitsandbytes_cpu.dylib' (no such file)\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/mlflow-venv/lib/python3.12/site-packages/bitsandbytes/cextension.py\", line 109, in <module>\n",
      "    lib = get_native_library()\n",
      "          ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/mlflow-venv/lib/python3.12/site-packages/bitsandbytes/cextension.py\", line 96, in get_native_library\n",
      "    dll = ct.cdll.LoadLibrary(str(binary_path))\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/mlflow-venv/lib/python3.12/ctypes/__init__.py\", line 460, in LoadLibrary\n",
      "    return self._dlltype(name)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/mlflow-venv/lib/python3.12/ctypes/__init__.py\", line 379, in __init__\n",
      "    self._handle = _dlopen(self._name, mode)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "OSError: dlopen(/opt/anaconda3/envs/mlflow-venv/lib/python3.12/site-packages/bitsandbytes/libbitsandbytes_cpu.dylib, 0x0006): tried: '/opt/anaconda3/envs/mlflow-venv/lib/python3.12/site-packages/bitsandbytes/libbitsandbytes_cpu.dylib' (no such file), '/System/Volumes/Preboot/Cryptexes/OS/opt/anaconda3/envs/mlflow-venv/lib/python3.12/site-packages/bitsandbytes/libbitsandbytes_cpu.dylib' (no such file), '/opt/anaconda3/envs/mlflow-venv/lib/python3.12/site-packages/bitsandbytes/libbitsandbytes_cpu.dylib' (no such file)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PeftModelForSequenceClassification(\n",
       "  (base_model): LoraModel(\n",
       "    (model): LlamaForSequenceClassification(\n",
       "      (model): LlamaModel(\n",
       "        (embed_tokens): Embedding(128256, 4096)\n",
       "        (layers): ModuleList(\n",
       "          (0-31): 32 x LlamaDecoderLayer(\n",
       "            (self_attn): LlamaSdpaAttention(\n",
       "              (q_proj): lora.Linear(\n",
       "                (base_layer): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=4096, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=4096, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "              )\n",
       "              (k_proj): lora.Linear(\n",
       "                (base_layer): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=4096, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=1024, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "              )\n",
       "              (v_proj): lora.Linear(\n",
       "                (base_layer): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=4096, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=1024, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "              )\n",
       "              (o_proj): lora.Linear(\n",
       "                (base_layer): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=4096, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=4096, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "              )\n",
       "              (rotary_emb): LlamaRotaryEmbedding()\n",
       "            )\n",
       "            (mlp): LlamaMLP(\n",
       "              (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
       "              (up_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
       "              (down_proj): Linear(in_features=14336, out_features=4096, bias=False)\n",
       "              (act_fn): SiLU()\n",
       "            )\n",
       "            (input_layernorm): LlamaRMSNorm()\n",
       "            (post_attention_layernorm): LlamaRMSNorm()\n",
       "          )\n",
       "        )\n",
       "        (norm): LlamaRMSNorm()\n",
       "      )\n",
       "      (score): ModulesToSaveWrapper(\n",
       "        (original_module): Linear(in_features=4096, out_features=3, bias=False)\n",
       "        (modules_to_save): ModuleDict(\n",
       "          (default): Linear(in_features=4096, out_features=3, bias=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = get_peft_model(model, lora_config)\n",
    "model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, add_prefix_space=True)\n",
    "\n",
    "tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model.config.pad_token_id = tokenizer.pad_token_id\n",
    "model.config.use_cache = False\n",
    "model.config.pretraining_tp = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Lemminkainen Oyj said that it has signed credit agreements with Nordea Bank STO : NDA, Pohjola Bank HEL : POH1S, Sampo Bank HEL : SAMAS and Svenska Handelsbanken STO : SHB A.',\n",
       " 'Pohjola could increase its stake to 45 % in 2013.']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences = df_test.sentence.tolist()\n",
    "sentences[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['PYTORCH_MPS_HIGH_WATERMARK_RATIO'] = '0.0'\n",
    "\n",
    "# Convert summaries to a list\n",
    "sentences = df_test.sentence.tolist()\n",
    "\n",
    "# Define the batch size\n",
    "batch_size = 32  # You can adjust this based on your system's memory capacity\n",
    "\n",
    "# Initialize an empty list to store the model outputs\n",
    "all_outputs = []\n",
    "\n",
    "# Process the sentences in batches\n",
    "for i in range(0, len(sentences), batch_size):\n",
    "    # Get the batch of sentences\n",
    "    batch_sentences = sentences[i:i + batch_size]\n",
    "\n",
    "    # Tokenize the batch\n",
    "    inputs = tokenizer(batch_sentences, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
    "\n",
    "    # Move tensors to the device where the model is (e.g., GPU or CPU)\n",
    "    \n",
    "    #inputs = {k: v.to('cuda' if torch.cuda.is_available() else 'cpu') for k, v in inputs.items()}\n",
    "    #inputs = {k: v.to('mps' if torch.backends.mps.is_available() else 'cpu') for k, v in inputs.items()}\n",
    "    device = 'mps' if torch.backends.mps.is_available() else 'cpu'\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "\n",
    "    # Perform inference and store the logits\n",
    "    with torch.no_grad():\n",
    "        #outputs = model.to(**inputs)\n",
    "        outputs = model(**inputs)\n",
    "        all_outputs.append(outputs['logits'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.6509, -0.9473, -2.3750],\n",
       "        [ 4.1680, -1.6211, -2.9375],\n",
       "        [ 0.1738, -2.8809,  1.8604],\n",
       "        [ 2.3516, -2.4668, -1.1201],\n",
       "        [ 1.6113, -2.0957, -0.4724],\n",
       "        [ 2.8984, -0.5962,  0.9126],\n",
       "        [ 2.9277, -0.3154, -1.1885],\n",
       "        [ 3.9121,  1.1055, -2.0527],\n",
       "        [ 5.0820, -1.0605, -2.1992],\n",
       "        [ 2.4922, -0.9614, -2.6367],\n",
       "        [ 2.2617, -0.6997,  1.4941],\n",
       "        [ 1.3232,  2.8262, -2.8047],\n",
       "        [ 2.2695,  0.9326, -0.8477],\n",
       "        [ 3.4688,  0.6050,  4.2383],\n",
       "        [ 5.5078,  1.2305, -2.9023],\n",
       "        [ 0.7168,  1.4990, -2.3848],\n",
       "        [ 3.6230, -4.5273,  0.7285],\n",
       "        [ 2.8965,  1.6641, -0.8125],\n",
       "        [ 2.1250, -0.1031, -1.1494],\n",
       "        [ 3.8418, -2.1113,  1.1719],\n",
       "        [ 0.3206, -3.1758, -2.8184],\n",
       "        [ 4.3086, -2.5469, -1.4219],\n",
       "        [ 3.5098, -0.4622, -0.0425],\n",
       "        [ 3.4336, -0.7734, -0.3809],\n",
       "        [ 3.4570, -0.8608, -0.1360],\n",
       "        [ 0.8315, -2.0391,  0.3950],\n",
       "        [ 1.0078, -4.6758,  0.9785],\n",
       "        [ 2.5469, -1.9199,  0.6440],\n",
       "        [ 1.8408, -2.9316,  3.1172],\n",
       "        [ 0.8042, -3.6035, -0.1011],\n",
       "        [ 1.7842, -0.0119,  0.2915],\n",
       "        [ 2.2969,  0.8242, -3.0742],\n",
       "        [ 5.6562, -2.6797, -0.2494],\n",
       "        [ 3.7227, -1.4785,  2.5918],\n",
       "        [ 3.8223, -0.2690, -2.7441],\n",
       "        [ 5.2422, -1.1270,  1.7822],\n",
       "        [ 3.1211,  0.7412,  1.5879],\n",
       "        [ 4.8047,  0.6548,  0.1095],\n",
       "        [ 1.8887, -0.0597, -2.1680],\n",
       "        [ 3.2891, -0.6606,  1.2637],\n",
       "        [ 3.3848, -3.0703, -0.2220],\n",
       "        [ 1.6592, -0.9175, -3.9941],\n",
       "        [ 2.4590, -0.7314,  1.7080],\n",
       "        [-1.7510, -3.1699,  2.3984],\n",
       "        [ 3.5254,  2.1992,  1.7441],\n",
       "        [ 3.1562, -2.3301, -0.3955],\n",
       "        [ 2.4941, -1.6455,  0.6782],\n",
       "        [ 1.8662, -0.0893, -4.4961],\n",
       "        [ 3.1543,  2.3770, -1.3779],\n",
       "        [ 1.5791, -1.8779,  0.4990],\n",
       "        [ 2.8848, -2.3242, -0.2720],\n",
       "        [ 2.7266, -3.8105, -0.3218],\n",
       "        [ 2.1426,  0.9580, -1.6885],\n",
       "        [ 1.2578, -1.2256, -1.4150],\n",
       "        [ 0.7612,  0.6152, -0.8491],\n",
       "        [ 2.2246,  0.8813, -0.7085],\n",
       "        [ 2.0879, -2.8008,  4.5781],\n",
       "        [ 3.7617, -1.1816, -3.0098],\n",
       "        [-0.9873, -3.1250, -0.6401],\n",
       "        [-1.0391, -3.2910, -0.3335],\n",
       "        [ 3.1055, -1.2051, -0.5640],\n",
       "        [ 1.7539, -1.2949,  0.5840],\n",
       "        [-0.3494, -3.5039,  1.7324],\n",
       "        [ 0.4563, -2.2949,  0.6035],\n",
       "        [-6.1406,  1.8311,  4.7734],\n",
       "        [ 0.6099, -0.2089,  1.0361],\n",
       "        [ 3.8164, -3.6094,  1.1367],\n",
       "        [ 4.7109, -1.1553,  3.2480],\n",
       "        [ 1.5420,  0.7534,  2.3184],\n",
       "        [-1.3076,  1.4805,  2.1133],\n",
       "        [ 1.4893, -1.9609, -0.9233],\n",
       "        [ 4.8750, -1.3428, -0.7070],\n",
       "        [ 3.3105, -0.8159,  0.9131],\n",
       "        [ 3.8008, -0.4836,  1.0693],\n",
       "        [ 5.4570, -3.2383, -0.6294],\n",
       "        [ 3.5020, -0.8062, -0.6763],\n",
       "        [ 2.1641,  2.9121, -0.6846],\n",
       "        [ 3.5820,  3.2832, -1.2207],\n",
       "        [ 0.7412, -1.8740,  3.5645],\n",
       "        [ 3.2598, -1.4023, -0.4573],\n",
       "        [ 1.5957,  0.3857, -2.3555],\n",
       "        [ 1.8047,  0.5908,  0.1605],\n",
       "        [ 2.7832, -0.6460, -1.8779],\n",
       "        [ 6.6875, -1.3164, -0.3188],\n",
       "        [ 1.0527, -1.1797,  1.5674],\n",
       "        [ 2.2422, -0.2949, -0.1595],\n",
       "        [ 1.7822, -2.0723,  0.7427],\n",
       "        [ 1.9512,  0.0673,  1.3770],\n",
       "        [ 1.7139, -2.4258,  6.6055],\n",
       "        [ 3.9082, -0.9302, -0.1205],\n",
       "        [ 0.0678, -3.3223, -2.2090],\n",
       "        [ 1.5762, -4.6992,  0.1392],\n",
       "        [ 1.9648, -2.4004, -1.2168],\n",
       "        [ 1.2734, -4.2188, -2.7422],\n",
       "        [ 4.7617, -0.1378, -1.0869],\n",
       "        [ 2.3340, -0.9150,  1.2256],\n",
       "        [ 1.8643, -1.1143, -1.1143],\n",
       "        [ 1.0107,  1.4414, -0.2771],\n",
       "        [ 4.4688, -0.4048, -2.4844],\n",
       "        [ 0.2644, -2.1934,  1.7686]], device='mps:0', dtype=torch.float16)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "final_outputs = torch.cat(all_outputs, dim=0)\n",
    "final_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 2, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 2, 2, 0, 0, 2, 2, 2, 2, 0, 0, 2, 2, 0, 0,\n",
       "        0, 0, 0, 0, 1, 0, 2, 0, 0, 0, 0, 0, 2, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 1, 0, 2], device='mps:0')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_outputs.argmax(axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/91/lyd666dn05368kh248wtmtdh0000gn/T/ipykernel_29564/1309614195.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_test['predictions']=final_outputs.argmax(axis=1).cpu().numpy()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "399    0\n",
       "400    0\n",
       "401    2\n",
       "402    0\n",
       "403    0\n",
       "      ..\n",
       "494    0\n",
       "495    0\n",
       "496    1\n",
       "497    0\n",
       "498    2\n",
       "Name: predictions, Length: 100, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df_test['predictions']=final_outputs.argmax(axis=1).cpu().numpy()\n",
    "df_test['predictions']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "predictions\n",
       "0    79\n",
       "2    17\n",
       "1     4\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test['predictions'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/91/lyd666dn05368kh248wtmtdh0000gn/T/ipykernel_29564/4293232383.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_test['predictions']=df_test['predictions'].apply(lambda l:category_map[l])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "399    negative\n",
       "400    negative\n",
       "401    positive\n",
       "402    negative\n",
       "403    negative\n",
       "         ...   \n",
       "494    negative\n",
       "495    negative\n",
       "496     neutral\n",
       "497    negative\n",
       "498    positive\n",
       "Name: predictions, Length: 100, dtype: object"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test['predictions']=df_test['predictions'].apply(lambda l:category_map[l])\n",
    "df_test['predictions']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_performance_metrics(df_test):\n",
    "  y_test = df_test.labels\n",
    "  y_pred = df_test.predictions\n",
    "\n",
    "  print(\"Confusion Matrix:\")\n",
    "  print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "  print(\"\\nClassification Report:\")\n",
    "  print(classification_report(y_test, y_pred))\n",
    "\n",
    "  print(\"Balanced Accuracy Score:\", balanced_accuracy_score(y_test, y_pred))\n",
    "  print(\"Accuracy Score:\", accuracy_score(y_test, y_pred))\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[ 3  0  0]\n",
      " [52  4  6]\n",
      " [24  0 11]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.04      1.00      0.07         3\n",
      "     neutral       1.00      0.06      0.12        62\n",
      "    positive       0.65      0.31      0.42        35\n",
      "\n",
      "    accuracy                           0.18       100\n",
      "   macro avg       0.56      0.46      0.21       100\n",
      "weighted avg       0.85      0.18      0.23       100\n",
      "\n",
      "Balanced Accuracy Score: 0.4596006144393241\n",
      "Accuracy Score: 0.18\n"
     ]
    }
   ],
   "source": [
    "get_performance_metrics(df_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 299/299 [00:00<00:00, 11747.10 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:00<00:00, 26504.29 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:00<00:00, 26240.64 examples/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "MAX_LEN = 512\n",
    "col_to_delete = ['sentence']\n",
    "\n",
    "def llama_preprocessing_function(examples):\n",
    "    return tokenizer(examples['sentence'], truncation=True, max_length=MAX_LEN)\n",
    "\n",
    "tokenized_datasets = dataset.map(llama_preprocessing_function, batched=True, remove_columns=col_to_delete)\n",
    "tokenized_datasets = tokenized_datasets.rename_column(\"target\", \"labels\")\n",
    "tokenized_datasets.set_format(\"torch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "collate_fn = DataCollatorWithPadding(tokenizer=tokenizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    return {'balanced_accuracy' : balanced_accuracy_score(predictions, labels),'accuracy':accuracy_score(predictions,labels)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomTrainer(Trainer):\n",
    "    def __init__(self, *args, class_weights=None, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        # Ensure label_weights is a tensor\n",
    "        if class_weights is not None:\n",
    "            self.class_weights = torch.tensor(class_weights, dtype=torch.float32).to(self.args.device)\n",
    "        else:\n",
    "            self.class_weights = None\n",
    "\n",
    "    def compute_loss(self, model, inputs, return_outputs=False):\n",
    "        # Extract labels and convert them to long type for cross_entropy\n",
    "        labels = inputs.pop(\"labels\").long()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(**inputs)\n",
    "\n",
    "        # Extract logits assuming they are directly outputted by the model\n",
    "        logits = outputs.get('logits')\n",
    "\n",
    "        # Compute custom loss with class weights for imbalanced data handling\n",
    "        if self.class_weights is not None:\n",
    "            loss = F.cross_entropy(logits, labels, weight=self.class_weights)\n",
    "        else:\n",
    "            loss = F.cross_entropy(logits, labels)\n",
    "\n",
    "        return (loss, outputs) if return_outputs else loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/mlflow-venv/lib/python3.12/site-packages/transformers/training_args.py:1494: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ğŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir = 'sentiment_classification',\n",
    "    learning_rate = 1e-4,\n",
    "    per_device_train_batch_size = 8,\n",
    "    per_device_eval_batch_size = 8,\n",
    "    num_train_epochs = 2,\n",
    "    weight_decay = 0.01,\n",
    "    evaluation_strategy = 'epoch',\n",
    "    save_strategy = 'epoch',\n",
    "    load_best_model_at_end = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/91/lyd666dn05368kh248wtmtdh0000gn/T/ipykernel_29564/2851958097.py:6: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.class_weights = torch.tensor(class_weights, dtype=torch.float32).to(self.args.device)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "trainer = CustomTrainer(\n",
    "    model = model,\n",
    "    args = training_args,\n",
    "    train_dataset = tokenized_datasets['train'],\n",
    "    eval_dataset = tokenized_datasets['val'],\n",
    "    tokenizer = tokenizer,\n",
    "    data_collator = collate_fn,\n",
    "    compute_metrics = compute_metrics,\n",
    "    class_weights=class_weights,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/07/07 06:53:44 INFO mlflow.tracking.fluent: Experiment with name 'test_240629_02' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='mlflow-artifacts:/1', creation_time=1720302824525, experiment_id='1', last_update_time=1720302824525, lifecycle_stage='active', name='test_240629_02', tags={}>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import mlflow\n",
    "\n",
    "\n",
    "os.environ['MLFLOW_S3_ENDPOINT_URL'] = 'http://localhost:9000'\n",
    "os.environ['AWS_ACCESS_KEY_ID'] = 'minioadmin'\n",
    "os.environ['AWS_SECRET_ACCESS_KEY'] = 'minioadmin'\n",
    "os.environ['MLFLOW_TRACKING_URI'] = 'http://localhost:5001'\n",
    "\n",
    "EXPERIMENT_NAME = \"test_240629_02\"\n",
    "mlflow.set_experiment(EXPERIMENT_NAME)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/76 [05:10<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Placeholder storage has not been allocated on MPS device!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[43], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m  model\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmps\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m#mlflow.transformers.log_model(transformers_model=model, artifact_path=\"my_pipeline\")\u001b[39;00m\n\u001b[1;32m      4\u001b[0m  \u001b[38;5;66;03m#mlflow.log_artifact('Dockerfile', artifact_path='my_pipeline')\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m  train_result \u001b[38;5;241m=\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/mlflow-venv/lib/python3.12/site-packages/transformers/trainer.py:1932\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1930\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   1931\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1932\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1933\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1934\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1935\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1936\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1937\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/mlflow-venv/lib/python3.12/site-packages/transformers/trainer.py:2268\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2265\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_step_begin(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n\u001b[1;32m   2267\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39maccumulate(model):\n\u001b[0;32m-> 2268\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2270\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   2271\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   2272\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[1;32m   2273\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misinf(tr_loss_step))\n\u001b[1;32m   2274\u001b[0m ):\n\u001b[1;32m   2275\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   2276\u001b[0m     tr_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/mlflow-venv/lib/python3.12/site-packages/transformers/trainer.py:3307\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   3304\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m loss_mb\u001b[38;5;241m.\u001b[39mreduce_mean()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m   3306\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_loss_context_manager():\n\u001b[0;32m-> 3307\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3309\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m inputs\n\u001b[1;32m   3311\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m {}\n",
      "Cell \u001b[0;32mIn[37], line 15\u001b[0m, in \u001b[0;36mCustomTrainer.compute_loss\u001b[0;34m(self, model, inputs, return_outputs)\u001b[0m\n\u001b[1;32m     12\u001b[0m labels \u001b[38;5;241m=\u001b[39m inputs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mlong()\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# Forward pass\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# Extract logits assuming they are directly outputted by the model\u001b[39;00m\n\u001b[1;32m     18\u001b[0m logits \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlogits\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/mlflow-venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/mlflow-venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/mlflow-venv/lib/python3.12/site-packages/peft/peft_model.py:1238\u001b[0m, in \u001b[0;36mPeftModelForSequenceClassification.forward\u001b[0;34m(self, input_ids, attention_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict, task_ids, **kwargs)\u001b[0m\n\u001b[1;32m   1236\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m peft_config\u001b[38;5;241m.\u001b[39mpeft_type \u001b[38;5;241m==\u001b[39m PeftType\u001b[38;5;241m.\u001b[39mPOLY:\n\u001b[1;32m   1237\u001b[0m             kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtask_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m task_ids\n\u001b[0;32m-> 1238\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbase_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1239\u001b[0m \u001b[43m            \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1240\u001b[0m \u001b[43m            \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1241\u001b[0m \u001b[43m            \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1242\u001b[0m \u001b[43m            \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1243\u001b[0m \u001b[43m            \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1244\u001b[0m \u001b[43m            \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1245\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1246\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1247\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1249\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m _get_batch_size(input_ids, inputs_embeds)\n\u001b[1;32m   1250\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m attention_mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1251\u001b[0m     \u001b[38;5;66;03m# concat prompt attention mask\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/mlflow-venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/mlflow-venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/mlflow-venv/lib/python3.12/site-packages/peft/tuners/tuners_utils.py:179\u001b[0m, in \u001b[0;36mBaseTuner.forward\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any):\n\u001b[0;32m--> 179\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/mlflow-venv/lib/python3.12/site-packages/transformers/models/llama/modeling_llama.py:1358\u001b[0m, in \u001b[0;36mLlamaForSequenceClassification.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1350\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1351\u001b[0m \u001b[38;5;124;03mlabels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\u001b[39;00m\n\u001b[1;32m   1352\u001b[0m \u001b[38;5;124;03m    Labels for computing the sequence classification/regression loss. Indices should be in `[0, ...,\u001b[39;00m\n\u001b[1;32m   1353\u001b[0m \u001b[38;5;124;03m    config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If\u001b[39;00m\n\u001b[1;32m   1354\u001b[0m \u001b[38;5;124;03m    `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\u001b[39;00m\n\u001b[1;32m   1355\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1356\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[0;32m-> 1358\u001b[0m transformer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1359\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1360\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1361\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1362\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1363\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1364\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1365\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1366\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1367\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1368\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1369\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m transformer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1370\u001b[0m logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscore(hidden_states)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/mlflow-venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/mlflow-venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/mlflow-venv/lib/python3.12/site-packages/transformers/models/llama/modeling_llama.py:931\u001b[0m, in \u001b[0;36mLlamaModel.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[0m\n\u001b[1;32m    928\u001b[0m     use_cache \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    930\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inputs_embeds \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 931\u001b[0m     inputs_embeds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membed_tokens\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    933\u001b[0m return_legacy_cache \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    934\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(past_key_values, Cache):  \u001b[38;5;66;03m# kept for BC (non `Cache` `past_key_values` inputs)\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/mlflow-venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/mlflow-venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/mlflow-venv/lib/python3.12/site-packages/torch/nn/modules/sparse.py:163\u001b[0m, in \u001b[0;36mEmbedding.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 163\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    164\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_norm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    165\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/mlflow-venv/lib/python3.12/site-packages/torch/nn/functional.py:2264\u001b[0m, in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   2258\u001b[0m     \u001b[38;5;66;03m# Note [embedding_renorm set_grad_enabled]\u001b[39;00m\n\u001b[1;32m   2259\u001b[0m     \u001b[38;5;66;03m# XXX: equivalent to\u001b[39;00m\n\u001b[1;32m   2260\u001b[0m     \u001b[38;5;66;03m# with torch.no_grad():\u001b[39;00m\n\u001b[1;32m   2261\u001b[0m     \u001b[38;5;66;03m#   torch.embedding_renorm_\u001b[39;00m\n\u001b[1;32m   2262\u001b[0m     \u001b[38;5;66;03m# remove once script supports set_grad_enabled\u001b[39;00m\n\u001b[1;32m   2263\u001b[0m     _no_grad_embedding_renorm_(weight, \u001b[38;5;28minput\u001b[39m, max_norm, norm_type)\n\u001b[0;32m-> 2264\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Placeholder storage has not been allocated on MPS device!"
     ]
    }
   ],
   "source": [
    "with mlflow.start_run() as run:\n",
    "    model.to('mps')\n",
    "   #mlflow.transformers.log_model(transformers_model=model, artifact_path=\"my_pipeline\")\n",
    "    #mlflow.log_artifact('Dockerfile', artifact_path='my_pipeline')\n",
    "    train_result = trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlflow-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
